Web page parsing techniques
===========================

This is a very incomplete start at listing different approaches and software tools for parsing web pages.

Crawling pages with dynamic content
-----------------------------------

A great many web page parsing programs and libraries exist today.  A challenge for most page-parsing systems is dynamic content introduced through the use of client-side scripting (usually via JavaScript) and dynamic state changes in the page DOM.  The following are some software tools that aim to handle such content.

* [ARCOMEM](https://sourceforge.net/p/arcomem/wiki/Architecture/)

* [Brozzler](https://github.com/internetarchive/brozzler)

* [CrawlJax](http://crawljax.com) &ndash; see also [this 2008 technical report](https://pdfs.semanticscholar.org/9b50/93c8b17aeb82f5c889021f979cb85645dc08.pdf) by Mesbah et al.

* [Nutch](http://soryy.com/blog/2014/ajax-javascript-enabled-parsing-apache-nutch-selenium/)

* [Portia](https://scrapinghub.com/portia/)

* [WAIL](https://github.com/N0taN3rd/wail)

* [StormCrawler](http://digitalpebble.blogspot.com/2017/04/crawl-dynamic-content-with-selenium-and.html)




Deep web crawling
-----------------
